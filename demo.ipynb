{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb96169-6e9b-410e-b6f3-9ce9ef09f486",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Demo\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/Demo-photo.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.fourier import circuit_spectrum\n",
    "from lecture08_helpers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create Target Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a067da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part of the code prints the graph we are trying to approximate\n",
    "\n",
    "degree = 4  # degree of the target function\n",
    "scaling = 1  # scaling of the data\n",
    "coeffs = [0.15 + 0.15j]*degree  # coefficients of non-zero frequencies\n",
    "coeff0 = 0.1  # coefficient of zero frequency\n",
    "\n",
    "def target_function(x):\n",
    "    \"\"\"Generate a truncated Fourier series, where the data gets re-scaled.\"\"\"\n",
    "    res = coeff0\n",
    "    for idx, coeff in enumerate(coeffs):\n",
    "        exponent = np.complex128(scaling * (idx+1) * x * 1j)\n",
    "        conj_coeff = np.conjugate(coeff)\n",
    "        res += coeff * np.exp(exponent) + conj_coeff * np.exp(-exponent)\n",
    "    return np.real(res)\n",
    "\n",
    "x = np.linspace(-6, 6, 70)\n",
    "target_y = np.array([target_function(x_) for x_ in x])\n",
    "\n",
    "\n",
    "plt.plot(x, target_y, c='black')\n",
    "plt.scatter(x, target_y, facecolor='white', edgecolor='black')\n",
    "plt.ylim(-5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Algorithim One \n",
    "\n",
    "In this section of the code we define the circuit with a variable n_layers and then get the frequencies folowing algorithim one outlined in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a VQC that changes based on the input n_layers which changes how many frequencies we can sample.\n",
    "\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "\n",
    "n_layers = 5\n",
    "dev = qml.device(\"default.qubit\", wires=1)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(x, weights):\n",
    "    for l in range(n_layers):\n",
    "        qml.RX(x, wires=0, id=\"x\"+str(0))\n",
    "        qml.Rot(weights[l,0,0], weights[l,0,1], weights[l,0,2], wires=0)\n",
    "    qml.RZ(x, wires=0, id=\"x0\")\n",
    "    return qml.expval(qml.PauliZ(wires=0))\n",
    "\n",
    "x = 1\n",
    "weights = np.random.random((n_layers, 1, 3))\n",
    "res = qml.fourier.circuit_spectrum(circuit)(x, weights)\n",
    "\n",
    "print(qml.draw(circuit)(x, weights))\n",
    "for inp, freqs in res.items():\n",
    "    print(f\"{inp}: {freqs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Inital graph for machine learning attempt in demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.fourier import circuit_spectrum\n",
    "from lecture08_helpers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "r = 1 # number of times the encoding gets repeated (here equal to the number of layers)\n",
    "weights = np.random.random((n_layers, 1, 3), requires_grad=True) # some random initial weights\n",
    "\n",
    "x = np.linspace(-6, 6, 70)\n",
    "# x = np.linspace(-6, 6, 10, requires_grad=False)\n",
    "random_quantum_model_y = [circuit(x_, weights) for x_ in x]\n",
    "\n",
    "plt.plot(x, random_quantum_model_y, c='blue')\n",
    "plt.ylim(-2,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Machine learning gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def square_loss(targets, predictions):\n",
    "    loss = 0\n",
    "    for t, p in zip(targets, predictions):\n",
    "        loss += (t - p) ** 2\n",
    "    loss = loss / len(targets)\n",
    "    return 0.5*loss\n",
    "\n",
    "def cost(weights, x, y):\n",
    "    predictions = [circuit(x_, weights) for x_ in x]\n",
    "    return square_loss(y, predictions)\n",
    "\n",
    "max_steps = 40\n",
    "opt = qml.AdamOptimizer(0.3)\n",
    "batch_size = 25\n",
    "cst = [cost(weights, x, target_y)]  # initial cost\n",
    "\n",
    "for step in range(max_steps):\n",
    "\n",
    "    # Select batch of data\n",
    "    batch_index = np.random.randint(0, len(x), (batch_size,))\n",
    "    x_batch = x[batch_index]\n",
    "    y_batch = target_y[batch_index]\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    weights, _, _ = opt.step(cost, weights, x_batch, y_batch)\n",
    "\n",
    "    # Save, and possibly print, the current cost\n",
    "    c = cost(weights, x, target_y)\n",
    "    cst.append(c)\n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(\"Cost at step {0:3}: {1}\".format(step + 1, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Gradient Descent output with short training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [circuit(x_, weights) for x_ in x]\n",
    "\n",
    "plt.plot(x, target_y, c='black')\n",
    "plt.scatter(x, target_y, facecolor='white', edgecolor='black')\n",
    "plt.plot(x, predictions, c='blue')\n",
    "plt.ylim(-2,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Algorithim 2 tree sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treelib import Node, Tree\n",
    "\n",
    "#The tree_sampling function creates a tree and then following the algorithim defined in the paper it creates and returns an array of frequencies that we can sample from.\n",
    "def tree_sampling(n_layers):\n",
    "    #Create a 2d array of eigenvalues\n",
    "    eigvals_array = []\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        pauli_x_eigval = qml.eigvals(qml.PauliX(wires=0))/2\n",
    "        eigvals_array.append(pauli_x_eigval)\n",
    "\n",
    "    pauli_z_eigval = qml.eigvals(qml.PauliZ(wires=0))/2\n",
    "    eigvals_array.append(pauli_z_eigval)\n",
    "\n",
    "    # Create the tree from the eigvals_array\n",
    "    # The depth of the tree will be n_layers + 1\n",
    "    def create_tree(eigvals, parent, depth):\n",
    "        if len(eigvals) == 0:\n",
    "            return None\n",
    "\n",
    "        first, *rest = eigvals\n",
    "\n",
    "        for i in range(len(first)):\n",
    "            node_name = parent + \"_\" + str(first[i]) + \"_\" + str(depth)\n",
    "            tree.create_node(node_name, node_name, parent=parent, data=first[i])\n",
    "            create_tree(rest, node_name, depth+1)\n",
    "\n",
    "    tree = Tree()\n",
    "    tree.create_node(\"root\", \"root\", data=0)  # root node\n",
    "    create_tree(eigvals_array, \"root\", 1)\n",
    "\n",
    "    # Function to sum the data values along each unique path starting from the leaves\n",
    "    def sum_from_leaves(tree, leaf_node):\n",
    "        path_sum = leaf_node.data\n",
    "        current_node = leaf_node\n",
    "\n",
    "        while str(current_node.identifier) != \"root\":\n",
    "            parent = tree.parent(current_node.identifier)\n",
    "            path_sum += parent.data\n",
    "            current_node = parent\n",
    "\n",
    "        return path_sum\n",
    "\n",
    "    upperCaseLambdaArray = []\n",
    "    # Calculate and print the sum of data values for each unique path starting from the leaves\n",
    "    for leaf in tree.leaves():\n",
    "        sum = sum_from_leaves(tree, leaf)\n",
    "        upperCaseLambdaArray.append(sum)\n",
    "\n",
    "    frequencyArray = []\n",
    "    #Create frequency array\n",
    "    for i in range(len(upperCaseLambdaArray)):\n",
    "        for j in range(len(upperCaseLambdaArray)):\n",
    "            frequency = upperCaseLambdaArray[i] - upperCaseLambdaArray[j]\n",
    "            frequencyArray.append(frequency)\n",
    "\n",
    "    return frequencyArray\n",
    "\n",
    "frequencyArray = tree_sampling(n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Algorithm 3 grid sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to create a range of floats for Algorithm 3\n",
    "def range_with_floats(start, stop, step):\n",
    "    while stop >= start:\n",
    "        yield start\n",
    "        start += step\n",
    "\n",
    "#Algorithim 3\n",
    "#Number of layers\n",
    "\n",
    "#For the circuit we use with each algorithm the number of encoding gates is number of layers + 1\n",
    "#This is because we have one additional encoding gate RZ.\n",
    "numberOfEncodingGates = n_layers + 1\n",
    "\n",
    "#Because the eigenvalues of PauliX and PauliZ gates are -0.5 and 0.5 we know that w_max is numberOfEncodingGates\n",
    "wMax = numberOfEncodingGates\n",
    "\n",
    "#We need to assign a step value a resonable step value is anywhere from 0 to 1\n",
    "step = 1\n",
    "\n",
    "grid = []\n",
    "\n",
    "#Create the grid\n",
    "for i in range_with_floats(0, wMax, step):\n",
    "    grid.append(i)\n",
    "\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Constructing the approximation function\n",
    "\n",
    "Classically training the approximation function to prepare for the algorithms. There is no gradient descent, as we can compute the optimization algorithm by explicitly computing $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_phi(x, frequencies):\n",
    "  #constructs phi or tilde_phi \n",
    "  #based on x and the given frequencies\n",
    "\n",
    "  phi = np.zeros(2* len(frequencies))\n",
    "  for i in range(len(frequencies)):\n",
    "    phi[2*i] = np.cos(frequencies[i] * x)\n",
    "    phi[2*i+1] = np.sin(frequencies[i] * x)\n",
    "  \n",
    "  return phi\n",
    "\n",
    "def construct_Phi(xi_array, frequencies):\n",
    "  M = len(xi_array)\n",
    "  P = 2*len(frequencies)\n",
    "  Phi = np.zeros((M, P))\n",
    "\n",
    "  for i in range(M):\n",
    "    phi = construct_phi(xi_array[i], frequencies)\n",
    "    for j in range(P):\n",
    "      Phi[i][j] = phi[j]\n",
    "  return Phi\n",
    "\n",
    "def construct_w(xi_array, yi_array, frequencies):\n",
    "  M = len(xi_array)\n",
    "  P = 2*len(frequencies)\n",
    "  Phi = construct_Phi(xi_array, frequencies)\n",
    "  lambda_hyper = 0.001\n",
    "\n",
    "  Phi_T = np.transpose(Phi)\n",
    "\n",
    "  w_1 = np.matmul(Phi_T, Phi) + M*lambda_hyper * np.identity(P)\n",
    "  w_2 = np.matmul(np.linalg.inv(w_1), Phi_T)\n",
    "  w = np.matmul(w_2, yi_array)\n",
    "  return w\n",
    "\n",
    "def f(x, w, frequencies):\n",
    "  phi = construct_phi(x, frequencies)\n",
    "  return np.matmul(w, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Output of target function that was quicker to train and just as accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-6, 6, 70)\n",
    "target_y = np.array([target_function(x_) for x_ in x])\n",
    "\n",
    "frequencies = res['x0']\n",
    "xi_array = x\n",
    "yi_array = target_y\n",
    "w = construct_w(xi_array, yi_array, frequencies)\n",
    "\n",
    "target_y_f = np.array([f(x_, w, frequencies) for x_ in x])\n",
    "\n",
    "plt.plot(x, target_y, c='black')\n",
    "plt.scatter(x, target_y, facecolor='white', edgecolor='black')\n",
    "plt.ylim(-2, 3)\n",
    "\n",
    "plt.plot(x, target_y_f, c='blue')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
